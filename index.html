---
layout: home
# articles:
#   excerpt_type: html
---
<html>
<head>
<title>Imagic: Text-Based Real Image Editing with Diffusion Models</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@200&display=swap" rel="stylesheet"> 
<style type="text/css">
.content {
    width:930px;
    text-align: left;
    font-family: 'Open Sans', sans-serif;
    font-weight: 200;
}
h1 {
    font-weight: 600;
}

table.authors {
    width:90%;
    text-align:center;
}
table.authors > tr > td, table.authors > tbody > tr > td {
    width:25%;
}
.authors a, .lnk {
    color:black;
    text-decoration:underline;
}
.authors a:hover, .lnk:hover {
    color:gray;
    text-decoration:underline;
}
.btn {
    color:black;
    text-decoration:none;
}
.btn:hover {
    color:gray;
    text-decoration:none;
}
table.demo1 {
    width:90%;
    text-align:center;
}
.demo1 img {
    width:300px;
}
td.prompt {
    width:100%;
    text-align:center;
    font-family: monospace;
    font-size:150%;
}
td.prompt a {
    color:#ddd;
    text-decoration:none;
}
td.prompt a:hover, td.prompt a.active {
    color:black;
    text-decoration:none;
}
.img-stack {
    position:relative;
    display: block;
    width:300px;
    height:300px;
}
.img-stack img {
    position: absolute;
    top: 0px;
    left: 0px;
    z-index: 0;
}
.img-stack img.active {
    z-index: 1;
}
.img-stack .overlay {
    width: 300px;
    height: 300px;
    opacity: 0;
    transition: opacity .2s;
    z-index: 2;
    position: absolute;
    top: 0px;
    left: 0px;
    background: white;
}
.carousel {
    position:relative;
    width:650px;
    height:385px;
    overflow:hidden;
}
.carousel > table {
    position:absolute;
    top: 0px;
    transition: left 1s;
    width:650px;
}
.carousel_table td {
    text-align:center;
}
.carousel_table td:nth-child(2) {
    font-size:150%;
}
pre {
    background-color:#eee;
    border: 1px solid #999;
    border-radius: 3px;
    padding: 3px;
white-space: break-spaces;
width:80%;
text-align:left;
}
td.gif {
    width: 33%;
    font-family: monospace;
    font-size: 120%;
}
.dl_link {
    display: inline-block;
    padding-right: 6px;
    padding-left: 6px;
    padding-top: 2px;
    padding-bottom: 2px;
}
.dl_link, .dl_link td {
    color: black;
    text-decoration: none;
    font-size: 120%;
}
.dl_link, .dl_link table {
    border-radius: 5px;
    background-color: none;
}
.dl_link:hover, .dl_link:hover * {
    color: #404040 !important;
    background-color: #d9d9d9 !important;
}
@media only screen and (max-width: 930px) {
    .content { width:100% !important; }
}
</style>
<center><div class="content">
      <h1>Benchmarking In-the-Wild Multimodal Plant Disease Recognition and A Versatile Baseline</h1>
      <table class="authors">
    <tr>
      <td><a href="https://orcid.org/0009-0005-0134-6438">Tianqi Wei</a></td>
      <td><a href="https://orcid.org/0000-0002-9385-144X">Zhi Chen</a></td>
      <td><a href="https://orcid.org/0000-0002-9738-4949">Zi Huang</a></td>
      <td><a href="https://orcid.org/0000-0002-0269-5649">Xin Yu</a></td>
    </tr> 
    <tr>
      <td style="padding-top:20px;"></td>
    </tr>
      </table><br />
<div align="left">
  <img width=850 src="cleaning.png"/>
</div>
</center>

<br />
<br />

<div id="abstract" style="border-top:1px solid gray;">
<h2>Introduction</h2>
<p>
Existing deep-learning methods have achieved remarkable performance in recognizing in-laboratory plant disease images. However, their performance often significantly degrades in classifying in-the-wild images.
Furthermore, we observed that in-the-wild plant images may exhibit similar appearances across various diseases (i.e., small inter-class discrepancy) while the same diseases may look quite different (i.e., large intra-class variance).
Motivated by this observation, we propose an in-the-wild multimodal plant disease recognition dataset, PlantWild, which contains the largest number of disease classes but also text-based descriptions for each disease. PlantWild is currently the largest dataset containing wild plant disease images.
</p>


<div align="left">
  <img width=850 src="plantwild.jpg"/>
</div>

Our PlantWild dataset can be regarded as an ideal testbed for evaluating disease recognition methods in the real world. 
The dataset is accessible through <a href="https://tqwei05.github.io/PlantWild/access">Download Page</a>. 
<br />
<br />

</div>  
  
<div id="abstract" style="border-top:1px solid gray;">
  <h2>Method</h2>
  <p>Code of our baseline MVPDR is available through <a href="https://github.com/tqwei05/MVPDR">https://github.com/tqwei05/MVPDR</a>.
The workflow of MVPDR is presented as the following figure.
It models text descriptions and visual data through multiple prototypes and can achieve outstanding performance on in-the-wild plant disease images.
<br />
<br />
<div align="left">
  <img width=550 src="baseline.png"/>
</div>

CLIP encoders extract features from images and text for each category and then multiple prototypes are constructed by grouping visual features. Given a test image, both the visual and textual prototypes can be used for classification.
Therefore, MVPDR can not only classify diseases but also recognize diseases in few-shot or training-free scenarios.</p>

</div>



<div id="paper" style="border-top:1px solid gray;">
    <h2>Paper</h2>
    <table><tr>
	<td valign="middle"><img src="thumbnail.png" style="width:200px;" /></td>
	<td valign="top">
	  <b>"Benchmarking In-the-Wild Multimodal Plant Disease Recognition and A Versatile Baseline"</b>,<br /><br/>
	  Tianqi Wei, Zhi Chen, Zi Huang, Xin Yu.<br /><br />
      ACM International Conference of Multimedia 2024<br /><br />
	  <b>[</b><a href="https://github.com/tqwei05/MVPDR" class="lnk">PDF</a><b>]</b>
	</td>
    </tr></table>
    </div><br />
    <div id="bibtex" style="border-top:1px solid gray;">
    <h2>BibTeX</h2>
    <center><pre><code>
      @inproceedings{MVPDR,
      title={Benchmarking In-the-Wild Multimodal Plant Disease Recognition and A Versatile Baseline},
      author={Wei, Tianqi and Chen, Zhi and Huang, Zi and Yu, Xin},
      booktitle={ACM International Conference of Multimedia},
      year={2024}}
    </code></pre></center>
    </div>
