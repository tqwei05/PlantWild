---
layout: home
# articles:
#   excerpt_type: html
---
<center><div class="content">
      <h1>Benchmarking In-the-Wild Multimodal Plant Disease Recognition and A Versatile Baseline</h1>
      <table class="authors">
    <tr>
      <td><a href="https://orcid.org/0009-0005-0134-6438">Tianqi Wei</td>
      <td><a href="https://orcid.org/0000-0002-9385-144X">Zhi Chen</td>
    </tr>
    <tr>
      <td><a href="https://orcid.org/0000-0002-9738-4949">Zi Huang</a></td>
      <td><a href="https://orcid.org/0000-0002-0269-5649">Xin Yu</a></td>
    </tr> 
    <tr>
      <td style="padding-top:20px;"></td>
    </tr>
      </table><br />
<div align="center">
  <img width=800 src="plantwild.jpg"/>
</div>
</center>

<div class="content">
Existing deep-learning methods have achieved remarkable performance in recognizing in-laboratory plant disease images. However, their performance often significantly degrades in classifying in-the-wild images.
Furthermore, we observed that in-the-wild plant images may exhibit similar appearances across various diseases (i.e., small inter-class discrepancy) while the same diseases may look quite different (i.e., large intra-class variance).
Motivated by this observation, we propose an in-the-wild multimodal plant disease recognition dataset that contains the largest number of disease classes but also text-based descriptions for each disease.
Our proposed dataset can be regarded as an ideal testbed for evaluating disease recognition methods in the real world.
</div>
